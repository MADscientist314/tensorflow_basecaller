{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"0_data_handler.ipynb","version":"0.3.2","provenance":[{"file_id":"1NLD0GUk3ovV7YopDUBirjSINQ5I0Tguu","timestamp":1542730146606}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"2MyzhVd_0D9w","colab_type":"code","colab":{}},"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import tensorflow as tf\n","import keras\n","import matplotlib.pyplot as plt\n","import re\n","import numpy as np\n","import os"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-qu-g8w3yPJe","colab_type":"code","colab":{}},"cell_type":"code","source":["# PARAMETERS CAN BE CHANGED HERE WITHOUT MESSING WITH THE CODE\n","kmersize=5\n","modelout=4**kmersize"],"execution_count":0,"outputs":[]},{"metadata":{"id":"s1Yz7_kKSqcX","colab_type":"code","colab":{}},"cell_type":"code","source":["#############QUICKLOADER##############\n","#x_train=np.load(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/x_train.npy\")\n","#y_train=np.load(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/y_train.npy\")\n","#reads=np.load(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/reads.npy\")\n","#readslength=np.load(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/readslength.npy\")\n","#reads_concat=np.load(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/reads_concat.npy\")\n","#metasig=np.load(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/metasig.npy\")\n","#metasig_concat=np.load(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/metasig_concat.npy\")\n","#sig=np.load(\"drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/sig_norm_concat.npy\")\n","#metasigcount=np.load(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/metasigcount.npy\")\n","#y_train=np.load(\"Users/algae/y_train.npy\")\n","#sig=np.load(\"Users/algae/sig_norm_concat.npy\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"-esczISXyPJi","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","this function divides the length of whatever \n","size the list is by 4 for a 4mer\n","\"\"\"\n","def BaseFunction(x,y): \n","    return((len(x)//y),y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sUPfIABvyPJm","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","this function divides the length of whatever \n","size the list is by 40 for a 40mer\n","\"\"\"\n","def SigFunction(x,y): \n","    return((y),((x//y)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"aL2DUadXyPJs","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","this function provides information about the array    \n","\"\"\"\n","def array_inspect(x):\n","    print (\"shape=\",(x.shape),\"len=\",len(x),\"ndim=\",x.ndim,\"size=\",x.size,\"dtype=\",x.dtype)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"xMU2m1DZyPJx","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","this function normalizes the raw signal resistances\n","from each read by dividing by the mean(or std?)\n","\"\"\"\n","def normalize(x,y):\n","    z=np.divide(x,y)\n","    return z"],"execution_count":0,"outputs":[]},{"metadata":{"id":"yMOJiSUpa92y","colab_type":"code","colab":{}},"cell_type":"code","source":["def plotsig(x):\n","  plt.ioff()\n","  plt.title(\"signal size\")\n","  plt.ylabel('signal size')\n","  plt.xlabel('read id')\n","  plt.plot(size)\n","  plt.show()\n","\n","  plt.ioff()\n","  plt.title(\"7mers\")\n","  plt.ylabel('#signals')\n","  plt.xlabel('read id')\n","  plt.plot(shape)\n","  plt.show()\n","\n","  plt.ioff()\n","  plt.title(\"signals per 7mer\")\n","  plt.ylabel('# signals')\n","  plt.xlabel('read id')\n","  plt.plot(shape2)\n","  plt.show()\n","\n","  plt.ioff()\n","  plt.title(\"signals per 7mer\")\n","  plt.ylabel('# signals')\n","  plt.xlabel('read id')\n","  plt.plot(shape2[0:100])\n","  plt.show()\n","\n","  plt.ioff()\n","  plt.title(\"signal length\")\n","  plt.ylabel('length of sig')\n","  plt.xlabel('read id')\n","  plt.plot(length)\n","\n","  plt.show()\n","  plt.ioff()\n","  plt.title(\"mean\")\n","  plt.ylabel('mean')\n","  plt.xlabel('read id')\n","  plt.plot(mean)\n","  plt.show()\n","\n","  plt.ioff()\n","  plt.title(\"standard deviation\")\n","  plt.ylabel('std dev')\n","  plt.xlabel('read id')\n","  plt.plot(std)\n","  plt.show()\n","\n","  plt.ioff()\n","  plt.title(\"variance\")\n","  plt.ylabel('var')\n","  plt.xlabel('read id')\n","  plt.plot(length)\n","  plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"jV828Y_BBh50","colab_type":"code","colab":{}},"cell_type":"code","source":["def BaseFunction(x,y): \n","    return((len(x)//y),y)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"o1-pIcjUHWg4","colab_type":"code","colab":{}},"cell_type":"code","source":["def translator(modelout):\n","  base = str(modelout)\n","  baseA0 = [re.sub(\"0\",\"A\",str) for str in base]\n","  baseT1 = [re.sub(\"1\",\"T\",str) for str in baseA0]\n","  baseG2 = [re.sub(\"2\",\"C\",str) for str in baseT1]\n","  base_coded = [re.sub(\"3\",\"G\",str) for str in baseG2] \n","  return (baseG2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6OMcPGPtfRlj","colab_type":"code","colab":{}},"cell_type":"code","source":["def processing (tsv, *args):\n","  b = (tsv.split(\" \", *args))\n","  print(\"There are\", len(b), \"number of reads in this file\")\n","  "],"execution_count":0,"outputs":[]},{"metadata":{"id":"zMEyO_4rjfEp","colab_type":"code","colab":{}},"cell_type":"code","source":["reads2=[]\n","for x in range(100):\n","  for y in range(len(reads[x])):\n","    for z in range(len(reads[x][y])):\n","      a=int(reads[x][y][z])\n","      reads2.append(a)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"t1KM3nhXk29A","colab_type":"code","colab":{}},"cell_type":"code","source":["reads2=np.array(reads2, dtype=int)\n","print(reads2[0:100])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZO0MutRUECx4","colab_type":"code","colab":{}},"cell_type":"code","source":["#DIVIDE THE READ INTO 7mers\n","kmer=[]\n","kmercount=[]\n","reads=[]\n","readslength=[]\n","f = open(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/reads-ref.eventalign.txt\", \"r\")\n","a = f.read()\n","processing(a)\n","np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/reads.npy\", reads)\n","readslength=np.array(readslength, dtype = int)\n","np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/readslength.npy\", readslength)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kswD96OauqC_","colab_type":"code","colab":{}},"cell_type":"code","source":["#sig=np.load(\"drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/sig_norm_concat.npy\")"],"execution_count":0,"outputs":[]},{"metadata":{"id":"VW9f-qVgMdrE","colab_type":"code","colab":{}},"cell_type":"code","source":["sigcount=[]\n","for x in range(len(sig)):\n","  b=len(sig[x])\n","  sigcount.append(b)\n","sigcount=np.array(sigcount, dtype=int)\n","print(\"The signal and read arrays have the same length:\", np.array_equal(sigcount, readslength))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Efa-UcP7YH3q","colab_type":"code","colab":{}},"cell_type":"code","source":["for x in range(len(sigcount)):\n","  if sigcount[x]==readslength[x]:\n","    None\n","  else:\n","    print(\"The signal and read arrays are different at:\", sigcount[x])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GTzITxMx-dGb","colab_type":"code","colab":{}},"cell_type":"code","source":["sig2=[]\n","for x in range(len(sig)):\n","  i=sig[x]\n","  for y in range(len(i)):\n","    z=i[y]\n","    sig2.append(z)\n","    #np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/sig2/sig_train_{}.npy\".format(x), z)\n","  if x%1000==0:\n","    print(\"sig\",x)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pGIYDap9ubGV","colab_type":"code","colab":{}},"cell_type":"code","source":["sig2 = np.array(sig2)\n","array_inspect(sig2)\n","np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/sig2/sig_train.npy\", sig2)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ZaponXbuKWD3","colab_type":"code","colab":{}},"cell_type":"code","source":["x_train=[]\n","for x in range(len(sig)): #4000\n","  a=len(sig[x]) #4000?\n","  for y in range(len(sig[x])):\n","    arr=sig[x][y] #725,46 or whtever\n","    split = np.array_split(arr, kmersize) #split the 1Darray of 7mer (46) into 7 pieces\n","    temp_arr = [arr.mean(), np.std(arr), np.var(arr)] # take the metadata of those 7 pieces\n","    for sarr in split:\n","      temp_arr.append(sarr.mean()) #take the mean of each of split up kmer signals\n","    x_train.append(arr) # make america great again\n","  if x%100==0:\n","    print(\"Step {} complete\".format(x))\n","x_train = np.array(x_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oLGNiLo_1TZP","colab_type":"code","colab":{}},"cell_type":"code","source":["print(x_train[0])\n","#x_train=np.array(x_train, dtype=float)\n","np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/x_train2.npy\", x_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"9VSM1Hj6veTu","colab_type":"code","colab":{}},"cell_type":"code","source":["array_inspect(x_train[0])\n","#array_inspect(x_train[0][0])\n","print(x_train[0][1])\n","print(x_train[0][2])\n","print(x_train[0][3])\n","print(x_train[0][4])\n","array_inspect(x_train[0][5])\n","array_inspect(x_train[0][6])\n","array_inspect(x_train[0][7])\n","array_inspect(x_train[0][8])\n","array_inspect(x_train[0][9])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"F81S5R7ba3nr","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","for x in range(len(x_train)):\n","  a=x_train[x]\n","  np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/x_train/x_train2_{}.npy\".format(x), a)\n","  if x%10000==0:\n","    print(\"x_train {} complete\".format(x))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IzPssrUAlB9_","colab_type":"code","colab":{}},"cell_type":"code","source":["#array_inspect(x_train)\n","#array_inspect(y_train)\n","#print(x_train[0])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"YG53pPyS2vXa","colab_type":"code","colab":{}},"cell_type":"code","source":["metasig=[]\n","for x in range(5):\n","  metasig7mer=[]\n","  for y in range(5):\n","      temp_arr=[]\n","      for z in range(len(sig[x][y])):\n","        a= sig[x][y][z]\n","        temp_arr2 = np.array([sig[x][y].mean(), np.std(sig[x][y]), np.var(sig[x][y]), a],  dtype=float)\n","        temp_arr.append(temp_arr2)\n","      metasig7mer.append(temp_arr)\n","  metasig7mer=np.array(metasig7mer, dtype=float)\n","  metasig.append(metasig7mer)\n","  if x%100==0: \n","    print(temp_arr)\n","    print(\"Finished sig_{}\".format(x)) \n","print(metasig[0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"L1VA_Vp743Fz","colab_type":"code","colab":{}},"cell_type":"code","source":["# This cell creates an array containing the mean, std, and var for the signal level events for each 7mer in all of the reads\n","# The array is 2D shape (#of signals,3) and is a float \n","\n","metasig=[]\n","for x in range(len(sig)):\n","  metasig7mer=[]\n","  for y in range(len(sig[x])):\n","      temp_arr=[]\n","      for z in range(len(sig[x][y])):\n","        temp_arr = np.array([sig[x][y].mean(), \n","        np.std(sig[x][y]), \n","        np.var(sig[x][y]), \n","        np.int16(sig([x][y])],  dtype=float)\n","      \n","      metasig7mer.append(temp_arr)\n","  metasig7mer=np.array(metasig7mer, dtype=float)\n","  metasig.append(metasig7mer)\n","  if x%100==0: \n","    print(temp_arr)\n","    print(\"Finished sig_{}\".format(x))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T8w7OB5uSKKQ","colab_type":"code","colab":{}},"cell_type":"code","source":["x_train_len = len(sig)\n","x_train =[None] * x_train_len\n","\n","for i in range(0, x_train_len):\n","  arr = sig[i]\n","  split = np.array_split(arr, kmersize)\n","  \n","  temp_arr = [arr.mean(), np.std(arr), np.var(arr)]\n","  \n","  for sarr in split:\n","    temp_arr.append(sarr.mean())\n","\n","  #temp_arr.append(len(set(arr)))\n","  \n","  x_train[i] = temp_arr\n","  \n","x_train = np.array(x_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"wbZ678Z_TOBa","colab_type":"code","colab":{}},"cell_type":"code","source":["for x in range (1):\n","  print(\"read {} mean is \".format(x), x_train[(x)][0])\n","  print(\"read {} stddev is \".format(x), x_train[(x)][1])\n","  print(\"read {} var is \".format(x), x_train[(x)][2])\n","  print(\"read {} 1bp mean is \".format(x), x_train[(x)][3])\n","  print(\"read {} 2bp mean is \".format(x), x_train[(x)][4])\n","  print(\"read {} 3bp mean is \".format(x), x_train[(x)][5])\n","  print(\"read {} 4bp mean is \".format(x), x_train[(x)][6])\n","  print(\"read {} 5bp mean is \".format(x), x_train[(x)][7])\n","  print(\"read {} 6bp mean is \".format(x), x_train[(x)][8])\n","  print(\"read {} 7bp mean is \".format(x), x_train[(x)][9])\n","array_inspect(x_train)\n","array_inspect(x_train[0])\n","array_inspect(sig)\n","array_inspect(sig[0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"4HBZAcNEcYFV","colab_type":"code","colab":{}},"cell_type":"code","source":["metasigcount=[]\n","for x in range(len(metasig)):\n","  x=len(metasig[x])\n","  metasigcount.append(x)\n","metasigcount=np.array(metasigcount, dtype = int)  \n","#print(\"The metasignal and raw__signal have the same length:\", np.array_equal(metasigcount, sigcount,))\n","#print(\"The metasignal and read arrays have the same length:\", np.array_equal(metasigcount, readslength))\n","np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/metasig.npy\", metasig)\n","np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/metasigcount.npy\", metasigcount)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"kYh4Vl7HX4vY","colab_type":"code","colab":{}},"cell_type":"code","source":["#This code concatentates the 4000 reads into concated 7mers\n","concat=[]\n","#array_inspect(reads)\n","for x in range (len(reads)):\n","  for y in range(len(reads[x])):\n","      temp_arr = reads[x][y]\n","      temp_arr=np.array(temp_arr, dtype=int)\n","      concat.append(temp_arr)\n","reads_concat=np.int16(concat)\n","array_inspect(reads_concat)\n","np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/reads_concat.npy\", reads_concat)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iZiIVZFfk8lg","colab_type":"code","colab":{}},"cell_type":"code","source":["print(reads_concat[0:10])\n","print(metasig[0][0])\n","print(len(metasig[0][0]))\n","print(len(reads[0][0]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hKg-FD8Df7Pp","colab_type":"code","colab":{}},"cell_type":"code","source":["metasig_concat=[]\n","for x in range (len(metasig)):\n","  for y in range(len(metasig[x])):\n","      temp_arr = metasig[x][y]\n","      concat.append(temp_arr)\n","  if x%1000==0:\n","    print(\"metasig\",(x))\n","metasig_concat=np.float64(concat)\n","array_inspect(metasig_concat)\n","np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/metasig_concat.npy\", metasig_concat)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8FF9rry3pogr","colab_type":"code","colab":{}},"cell_type":"code","source":["train_set=[]\n","for x in range(len(reads_concat)):\n","  a=(reads_concat[x], metasig_concat[x])\n","  train_set.append(a)\n","  if x%1000000==0:\n","    print(\"train_set\",x)\n","train_set=np.array(train_set)\n","np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/train_set.npy\", train_set)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"m4HHsXCvZzN5","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"th2iDsFGyPKK","colab_type":"code","colab":{}},"cell_type":"code","source":["\"\"\"\n","The cell does the following:\n","    1) Import the signal level data\n","    2) Normalize it to the mean fof the signal\n","    3) Appends the signal data from each read into a row of an array given the read count\n","\"\"\"\n","#1) LOAD THE PREVIOUSLY ARRANGED AND NORMALIZED DATA\n","\n","#sig = np.load(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/sig_norm_concat.npy\")\n","\n","\n","#2)APPEND THE SIGNAL DATA FROM EACH READ INTO A ROW OF AN ARRAY GIVEN THE READ COUNT\n","\n","#means = [] \n","#std = []\n","#sig = []\n","#sig2 = []\n","#for x in range(4000):\n","    #a=np.loadtxt(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/signal2/signal/signel_{}.txt\".format(x), delimiter='\\n') # load the signal\n","    #m=a.mean() #obtain the average signal from the read\n","    #b=normalize(m,a) # divide each resistance by the average to normalize \n","    #c=b.size #obtains the number of resistance signals per read\n","    #print(\"resist\",c)\n","    #d=readslength[x+1] #obtains the kmers count per read\n","    #print(\"kmer\",d)\n","    #e=SigFunction(c,d) #figures out the average amount of resistances per kmer\n","    #print(\"Signal\",x,\"2D array size={}\".format(e))\n","    #sig2.append(a)\n","    #b.resize(e) # Insert the (#bases,#sig) changes the signal level n signals wide\n","    #sig.append(b)\n","    #np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/signal2/signalnorm/numpy/sig_norm_{}.npy\".format(x), b)\n","    #if x%5==0:\n","    #  print(\"Finished signal_{}.txt\".format(x))\n","#np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/sig_norm_concat.npy\", sig)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"pnYIM17qzeO8","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]},{"metadata":{"id":"MtvUcb6EyPKO","colab_type":"code","colab":{}},"cell_type":"code","source":["digits = \"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZ\"\n","\n","def int2str(x, base):\n","    if x < 0:\n","        return \"-\" + int2str(-x, base)\n","    return (\"\" if x < base else int2str(x//base, base)) + digits[x % base]\n","\n","dict = {}\n","dict2 ={}\n","\n","for i in range(4 ** kmersize):\n","    key = int2str(i,4).zfill(kmersize)\n","    dict[key] = i\n","    dict2[i] = key\n","converted2=[]\n","for x in range(len(reads)):\n","  for v in arr2:\n","      converted2.append(dict[v])\n","      if v%5000==0:\n","        print(\"Finished append_{}.txt\".format(v))\n","\n","a=np.unique(arr2) # makes an array of every unique combo in the read for downstream indexing\n","y_train=np.int16(arr2)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"26JLzqejNzpG","colab_type":"code","colab":{}},"cell_type":"code","source":["array_inspect(reads[0:4000])\n","array_inspect(reads_concat)\n","array_inspect(sig)\n","#array_inspect(metasig)\n","y_train=reads[0:4000]\n","y_test= reads[0:4000]\n","x_train=sig\n","x_test=sig"],"execution_count":0,"outputs":[]},{"metadata":{"id":"EbqqjlVuyPKT","colab_type":"code","colab":{}},"cell_type":"code","source":["#HEEEEEEEELPPPPP MEEEEE HERRRRREEEEEE\n","# I need to concat all 4000 reads into this dic\n","\n","\n","\"\"\"\n","The goal for this cell is to convert the reads to string\n","index the unique outputs for the 4mers\n","and create a new list of the indexed [1:256 or whatever]\n","reads for the model\n","\"\"\"\n","\n","arr2=[] # In this code I converted the reads to a concated string of a 4mer\n","converted=[]\n","converted2=[]\n","for i, v in enumerate(reads[12]): #Read 0 is the training data\n","    temp = ''\n","    for w in v:\n","        temp = temp + str(w)\n","    arr2.append(temp)\n","    \n","for v in arr2:\n","    converted2.append(dict[v])\n","    \n","a=np.unique(arr2) # makes an array of every unique combo in the read for downstream indexing\n","y_train=np.int16(converted2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"qoYI-eeqNWM0","colab_type":"code","colab":{}},"cell_type":"code","source":["a=np.unique(y_train)\n","print(a.size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"J1rPpENmddtN","colab_type":"code","colab":{}},"cell_type":"code","source":["#print(len(arr2))\n","#np.save(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/arr2.npy\", arr2)\n","converted2=[]\n","for x in range(len(reads)):\n","  for v in arr2:\n","      converted2.append(dict[v])\n","      if v%5000==0:\n","        print(\"Finished append_{}.txt\".format(v))\n","\n","a=np.unique(arr2) # makes an array of every unique combo in the read for downstream indexing\n","y_train=np.int16(arr2)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"iLcvQ6ZcyPKZ","colab_type":"code","colab":{}},"cell_type":"code","source":["arr2=np.load(\"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/datasets/arr2.npy\", arr2)\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"XYlv0KV_yPKi","colab_type":"code","colab":{}},"cell_type":"code","source":["y_test=y_train\n","\n","#I just copied the same code for the testing set read(1)\n","\n","#arr2=[] # In this code I converted the reads to a concated string of a 4mer\n","converted=[]\n","converted2=[]\n","for i, v in enumerate(reads_concat): #Read 0 is the training data\n","    temp = ''\n","    for w in v:\n","        temp = temp + str(w)\n","    arr2.append(temp)\n","a=np.unique(arr2)# makes an array of every unique combo in the read for downstream indexing\n","y_test=np.int16(converted2)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"deGp6IToyPKr","colab_type":"code","colab":{}},"cell_type":"code","source":["print(a.size)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"IduYnrNvyPKy","colab_type":"code","colab":{}},"cell_type":"code","source":["x_train = sig\n","x_test = sig\n","array_inspect(x_train)\n","array_inspect(x_test)\n","(i,j) = x_train.shape"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hMSM3ZBKqdP2","colab_type":"code","colab":{}},"cell_type":"code","source":["x_train_len = len(x_train)\n","x_train2 =[None] * x_train_len\n","\n","for i in range(0, x_train_len):\n","  arr = x_train[i]\n","  \n","  temp_arr = [arr.mean(), np.std(arr), arr.max(), arr.min(), len(set(arr))]\n","\n","  #temp_arr.append(len(set(arr)))\n","  \n","  x_train2[i] = temp_arr\n","  \n","x_train2 = np.array(x_train2)\n","print(x_train2[0:2])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NY2ARsXOwiZk","colab_type":"code","colab":{}},"cell_type":"code","source":["print(x_train2.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"7SVFHxBGyPK7","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","model=tf.keras.models.Sequential()\n","model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu)) # uses 128 neurons and is a feed forward rectilinear relu\n","model.add(tf.keras.layers.Dropout(0.2))\n","model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))\n","model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu)) # do the same thig for hidden layer 2\n","model.add(tf.keras.layers.Dense(modelout, activation=tf.nn.softmax)) # output layer with number of classifications (256) use softmax for output distribution\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"B5fAbtMMyPK_","colab_type":"code","colab":{}},"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n"],"execution_count":0,"outputs":[]},{"metadata":{"id":"gkWWshaO68Fq","colab_type":"code","colab":{}},"cell_type":"code","source":["checkpoint_path = \"/content/drive/My Drive/Colab Notebooks/tensorflow_basecaller/training_7mer/jochum_cp1.ckpt\"\n","checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, monitor='loss', \n","                                      verbose=1, \n","                                      save_weights_only=True, \n","                                                \n","                                      mode='min')\n","callbacks_list = [checkpoint]\n","#Create checkpoint callback\n","#cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n"," #                                               save_weights_only=True,\n","  #                                               verbose=1)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8k2aRGZR7Qze","colab_type":"code","colab":{}},"cell_type":"code","source":["#model.load_weights(checkpoint_path)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3cmj49mryPLC","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","x_val = x_train[:1000]\n","partial_x_train = x_train[1000:10000]\n","y_val = y_train[:1000]\n","partial_y_train = y_train[1000:10000]\n","\n","history = model.fit(partial_x_train,\n","                    partial_y_train,\n","                    epochs=689,\n","                    validation_data=(x_val, y_val),\n","                    batch_size=300,\n","                    verbose=1,\n","                    callbacks = callbacks_list)\n","model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"_auNTHszyPLV","colab_type":"code","colab":{}},"cell_type":"code","source":["results = model.evaluate(x_train, y_train)\n","\n","print(results)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"QIYVwMlhGP_P","colab_type":"code","colab":{}},"cell_type":"code","source":["min_pred = 1\n","max_pred = min_pred+1\n","arr = np.array([x_train[min_pred][::-1]])\n","\n","preds = model.predict(x_train[min_pred:max_pred])\n","preds2 = model.predict(arr)\n","print(x_train[min_pred:max_pred])\n","print(arr)\n","print(preds)\n","print(preds2)\n","print(np.argmax(preds[0]))\n","print(np.argmax(preds2[0]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"84xTiyRmfRHZ","colab_type":"code","colab":{}},"cell_type":"code","source":["print(y_train.shape)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Yh4W3teIgtsY","colab_type":"code","colab":{}},"cell_type":"code","source":["import keras\n","evaluate(x=None, y=None, batch_size=None, verbose=1, sample_weight=None, steps=None)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5s_WAC63yPLa","colab_type":"code","colab":{}},"cell_type":"code","source":["#x_train.resize(392226, 26,1)\n","#array_inspect(x_train)\n","#x_test.resize(392226, 26,1)\n","#array_inspect(x_train)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"8sRQxzManlJI","colab_type":"code","colab":{}},"cell_type":"code","source":["concat_reads = ''\n","concat_reads2 = ''\n","concat_ref = ''\n","\n","for arr in preds:\n","  concat_reads += str(dict2[np.argmax(arr)])\n","  \n","for arr in preds2:\n","  concat_reads2 += str(dict2[np.argmax(arr)])\n","\n","for arr in y_train[min_pred:max_pred]:\n","  concat_ref += str(dict2[arr])\n","\n","print(concat_reads)\n","print(concat_reads2[::-1])\n","print(concat_ref)\n","\n","read_len = len(concat_reads)\n","accurate = 0\n","\n","for i in range(0,read_len):\n","  if concat_reads[i] == concat_ref[i]:\n","    accurate+=1\n","\n","print(accurate/read_len)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"KeNVKbnTyPLd","colab_type":"code","colab":{}},"cell_type":"code","source":["\n","#checkpoint_path = \"training_2/cp.ckpt\"\n","#checkpoint_dir = os.path.dirname(checkpoint_path)\n","\n","# Create checkpoint callback\n","#cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True,verbose=1)\n","\n","\n","#model=tf.keras.models.Sequential()\n","#model.add(tf.keras.layers.CuDNNLSTM(128, input_shape=(x_train.shape[1:]))) # uses 128 neurons and is a feed forward rectilinear relu\n","#model.add(tf.keras.layers.Dropout(0.2))\n","#model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu))\n","#model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))\n","#model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))\n","# do the same thig for hidden layer 2\n","#model.add(tf.keras.layers.Flatten())\n","#model.add(tf.keras.layers.Dense(2048, activation='relu')) # do the same thig for hidden layer 2\n","#model.add(tf.keras.layers.Dropout(0.2))\n","\n","#model.add(tf.keras.layers.Dense(1024, activation='softmax')) # output layer with number of classifications (256) use softmax for output distribution"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0zISJ6lgyPLi","colab_type":"code","colab":{}},"cell_type":"code","source":["#model.compile(optimizer='adam',\n","#              loss='sparse_categorical_crossentropy',\n","#              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5s36sC7EyPLl","colab_type":"code","colab":{}},"cell_type":"code","source":["#x_val = x_train[:1000]\n","#partial_x_train = x_train\n","\n","#y_val = y_train[:1000]\n","#partial_y_train = y_train\n","\n","#history = model.fit(partial_x_train,\n","#                    partial_y_train,\n","#                    epochs=100,\n","#                    validation_data=(x_val, y_val),\n","#                    batch_size=1256,\n","#                    verbose=1,\n","#                    callbacks = [cp_callback])\n","#model.summary()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"DwHm5DC8yPLr","colab_type":"code","colab":{}},"cell_type":"code","source":["#results = model.evaluate(x_train, y_train)\n","\n","#print(results)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"MNrlQsV4yPLv","colab_type":"code","colab":{}},"cell_type":"code","source":["history_dict = history.history\n","history_dict.keys()\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs = range(1, len(acc) + 1)\n","\n","# \"bo\" is for \"blue dot\"\n","plt.plot(epochs, loss, 'bo', label='Training loss')\n","# b is for \"solid blue line\"\n","plt.plot(epochs, val_loss, 'b', label='Validation loss')\n","plt.title('Training and validation loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vyoHHlyTyPL2","colab_type":"code","colab":{}},"cell_type":"code","source":["plt.clf()   # clear figure\n","acc_values = history_dict['acc']\n","val_acc_values = history_dict['val_acc']\n","\n","plt.plot(epochs, acc, 'bo', label='Training acc')\n","plt.plot(epochs, val_acc, 'b', label='Validation acc')\n","plt.title('Training and validation accuracy')\n","plt.xlabel('Epochs')\n","plt.ylabel('Accuracy')\n","plt.legend()\n","\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Xz8oK05YyPL5","colab_type":"code","colab":{}},"cell_type":"code","source":["print(np.argmax(sig[0])) #why is 85 the max number"],"execution_count":0,"outputs":[]},{"metadata":{"id":"JJb0Zv0SyPMA","colab_type":"code","colab":{}},"cell_type":"code","source":["array_inspect(x_test)\n","array_inspect(y_test)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1LqXnZR2yPME","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}