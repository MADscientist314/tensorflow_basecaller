{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "import csv\n",
    "import h5py\n",
    "import signal\n",
    "import fast5\n",
    "import fastq\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "checks to see if gpu is working\n",
    "\"\"\"\n",
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this function divides the length of whatever \n",
    "size the list is by 4 for a 4mer\n",
    "\"\"\"\n",
    "def BaseFunction(x,y): \n",
    "    return((len(x)//y),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this function divides the length of whatever \n",
    "size the list is by 40 for a 40mer\n",
    "\"\"\"\n",
    "def SigFunction(x,y): \n",
    "    return((y),((x//y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this function provides information about the array    \n",
    "\"\"\"\n",
    "def array_inspect(x):\n",
    "    print (\"Shape is\",(x.shape))\n",
    "    print((\"Length is\",len(x)))\n",
    "    print((\"Dimension is\",x.ndim))\n",
    "    print((\"Total Size is\",x.size))\n",
    "    print((\"Type is\",x.dtype))\n",
    "    print((\"Type Name is\",x.dtype.name))\n",
    "    #print((\"Mean is\",(x).mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this function normalizes the raw signal resistances\n",
    "from each read by dividing by the mean(or std?)\n",
    "\"\"\"\n",
    "def normalize(x,y):\n",
    "    z=np.divide(x,y)\n",
    "    #np.savetxt(\"NormalizedSigArray_{}.csv\".format(),(z), delimiter=\",\")\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divider(x,y):\n",
    "    a=np.divide(x,y)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fxnAxes(x):\n",
    "    a=fig.add_axes([0.(x), 0.(x), 0.(x+1), 0.(x+1)])    \n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell does the following\n",
    "    1)Imports the bases\n",
    "    2)trims off the new lines and digits\n",
    "    3)converts them to a list\n",
    "    4)converts them to a code of 0123 instead of ATCG\n",
    "\"\"\"\n",
    "f = open(\"fasta/sampled_read_concat.fasta\",\"r\") #opens the file with the reads\n",
    "a = f.read()\n",
    "b = (a.split(\">\", 11))\n",
    "base = [re.sub(\">|\\n|\\d\", \"\",str) for str in b]\n",
    "baseA0 = [re.sub(\"A\",\"0\",str) for str in base]\n",
    "baseT1 = [re.sub(\"T\",\"1\",str) for str in baseA0]\n",
    "baseG2 = [re.sub(\"C\",\"2\",str) for str in baseT1]\n",
    "base_coded = [re.sub(\"G\",\"3\",str) for str in baseG2] \n",
    "A0=(a.count(\"A\")) \n",
    "T1=(a.count(\"T\"))\n",
    "G2=(a.count(\"G\"))\n",
    "C3=(a.count(\"C\"))\n",
    "#print(base_coded)\n",
    "names = ['A', 'T', 'G', 'C']\n",
    "values = [(A0), (T1), (G2), (C3)]\n",
    "\n",
    "plt.subplot()\n",
    "plt.bar(names, values)\n",
    "plt.suptitle('Nucleotides in all reads')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The purpose of this code is the following\n",
    "1)Convert the coded reads to integer form \n",
    "2)Create an array inside the array with each read as a row\n",
    "3)Create a 2D matric with the counts of all the possible scenarios \n",
    "presented in each row and the reads in each column\n",
    "4)Create a 1D array with the readlengths\n",
    "\"\"\"\n",
    "kmer=[]\n",
    "kmercount=[]\n",
    "reads=[]\n",
    "#readstring={}\n",
    "readslength=[]\n",
    "res=(len(base_coded))   \n",
    "for x in range(res):\n",
    "    l=list(int (i) for i in base_coded[x])\n",
    "    for y in range(1):\n",
    "        i=(l.count(y), l.count(y+1), l.count(y+2), l.count(y+3))\n",
    "        kmercount.append(i)\n",
    "        n=np.transpose(kmercount) # creates a 2D matrix with the bases counts as rows(ATGC) and the reads by columns\n",
    "        kmer = n.view() #Create a view of the array with the same data\n",
    "    d=np.asarray(l)\n",
    "    d.resize((BaseFunction(d,4))) #Enter the list and the desired kmer for the function\n",
    "    v=(str(d))\n",
    "    reads.append(d) # store the reads in an array called reads\n",
    "    c=len(d)\n",
    "    readslength.append(c) #store the amt of kmer reads in readlength="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is (11063, 4)\n",
      "('Length is', 11063)\n",
      "('Dimension is', 2)\n",
      "('Total Size is', 44252)\n",
      "('Type is', dtype('int32'))\n",
      "('Type Name is', 'int32')\n"
     ]
    }
   ],
   "source": [
    "array_inspect(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89083248 0.89083248 0.89083248 ... 0.88536502 0.88536502 0.88536502]\n",
      "310933\n",
      "11063\n",
      "(11063, 28)\n",
      "Shape is (11063, 28)\n",
      "('Length is', 11063)\n",
      "('Dimension is', 2)\n",
      "('Total Size is', 309764)\n",
      "('Type is', dtype('float64'))\n",
      "('Type Name is', 'float64')\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The cell does the following:\n",
    "    1) Import the signal level data\n",
    "    2) Normalize it to the mean fof the signal\n",
    "    3) Appends the signal data from each read into a row of an array given the read count\n",
    "\"\"\"\n",
    "means = [] \n",
    "std = []\n",
    "sig = []\n",
    "a=np.loadtxt(\"signal/signal_concat.txt\") # load the signal\n",
    "m=a.mean() #obtain the average signal from the read\n",
    "b=normalize(m,a) # divide each resistance by the average to normalize \n",
    "print (b)\n",
    "c=b.size #obtains the number of resistance signals per read\n",
    "    #print(\"resist\",c)\n",
    "print(c)\n",
    "f=len(d) #obtains the kmers count per read\n",
    "print(f)    #print(\"kmer\",d)ch\n",
    "def SigFunction(x,y): \n",
    "    return((y),((x//y)))\n",
    "e=SigFunction(c,f) #figures out the average amount of resistances per kmer\n",
    "print(e)    #print(\"Signal\",x,\"2D array size={}\".format(e))\n",
    "b.resize(e) # Insert the (#bases,#sig) changes the signal level n signals wide\n",
    "    #we can change this number later to be a sliding window for maching learning\n",
    "sig.append(b)\n",
    "    #array_inspect(sig[x])\n",
    "    #np.savetxt('sig_array.csv', b, delimiter=',')\n",
    "\n",
    "array_inspect(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The purpose of this cell is to merge the reads and the raw signals together\\nI dont really remember why I was doing this, but I am now using it to export \\nthe csv array into another file where I will launch tensorflow\\n'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"The purpose of this cell is to merge the reads and the raw signals together\n",
    "I dont really remember why I was doing this, but I am now using it to export \n",
    "the csv array into another file where I will launch tensorflow\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAny cell under this cell is trash code or experimental\\n'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Any cell under this cell is trash code or experimental\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing training data (inputs-outputs)  \n",
    "training_inputs = tensorflow.placeholder(shape=[None, 28], dtype=tensorflow.float32)  \n",
    "training_outputs = tensorflow.placeholder(shape=[None, 1], dtype=tensorflow.float32) #Desired outputs for each input  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing neural network parameters (weights and bias) using TensorFlow Variables  \n",
    "weights = tensorflow.Variable(initial_value=[[.3], [.1], [.8]] , dtype=tensorflow.float32)  \n",
    "bias = tensorflow.Variable(initial_value=[[1]], dtype=tensorflow.float32)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Dimensions must be equal, but are 28 and 3 for 'MatMul_10' (op: 'MatMul') with input shapes: [?,28], [3,1].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\users\\algae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1625\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1626\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1627\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Dimensions must be equal, but are 28 and 3 for 'MatMul_10' (op: 'MatMul') with input shapes: [?,28], [3,1].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-be3026876497>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Preparing inputs of the activation function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maf_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Training entries: {}, labels: {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\algae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, name)\u001b[0m\n\u001b[0;32m   2051\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2052\u001b[0m       return gen_math_ops.mat_mul(\n\u001b[1;32m-> 2053\u001b[1;33m           a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0m\u001b[0;32m   2054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2055\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\algae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   4854\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m   4855\u001b[0m         \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4856\u001b[1;33m         name=name)\n\u001b[0m\u001b[0;32m   4857\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4858\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\algae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    785\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[0;32m    786\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m                          op_def=op_def)\n\u001b[0m\u001b[0;32m    788\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_stateful\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\algae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m                 \u001b[1;34m'in a future version'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'after %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m                 instructions)\n\u001b[1;32m--> 488\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m     return tf_decorator.make_decorator(func, new_func, 'deprecated',\n\u001b[0;32m    490\u001b[0m                                        _add_deprecated_arg_notice_to_docstring(\n",
      "\u001b[1;32mc:\\users\\algae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m   3270\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3271\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3272\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3273\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3274\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\algae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1788\u001b[0m           op_def, inputs, node_def.attr)\n\u001b[0;32m   1789\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, grouped_inputs,\n\u001b[1;32m-> 1790\u001b[1;33m                                 control_input_ops)\n\u001b[0m\u001b[0;32m   1791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1792\u001b[0m     \u001b[1;31m# Initialize self._outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\algae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1628\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1629\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1630\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1631\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Dimensions must be equal, but are 28 and 3 for 'MatMul_10' (op: 'MatMul') with input shapes: [?,28], [3,1]."
     ]
    }
   ],
   "source": [
    "# Preparing inputs of the activation function  \n",
    "af_input = tensorflow.matmul(training_inputs, weights) + bias\n",
    "print(\"Training entries: {}, labels: {}\".format(len(d), len(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activation function of the output layer neuron  \n",
    "predictions = tensorflow.nn.sigmoid(af_input)\n",
    "# Measuring the prediction error of the network after being trained  \n",
    "prediction_error = tensorflow.reduce_sum(training_outputs - predictions)\n",
    "# Minimizing the prediction error using gradient descent optimizer  \n",
    "train_op = tensorflow.train.GradientDescentOptimizer(learning_rate=0.05).minimize(prediction_error)  \n",
    "# Creating a TensorFlow Session  \n",
    "sess = tensorflow.Session()\n",
    "# Initializing the TensorFlow Variables (weights and bias)  \n",
    "sess.run(tensorflow.global_variables_initializer()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 1 0]\n",
      " [3 1 1 3]\n",
      " [3 0 1 3]\n",
      " ...\n",
      " [3 1 1 1]\n",
      " [2 3 0 3]\n",
      " [0 1 1 1]]\n",
      "['1310' '3113' '3013' ... '3111' '2303' '0111']\n"
     ]
    }
   ],
   "source": [
    "arr2=[] # In this code I converted the reads to a concated string of a 4mer\n",
    "arr3=[]\n",
    "print(d)\n",
    "for i,v in enumerate(d):\n",
    "    temp = ''\n",
    "    for w in v:\n",
    "        temp = temp + str(w)\n",
    "    arr2.append(temp)\n",
    "y_val = np.array(arr2)\n",
    "partial_y_train = (y_val[0:5000])\n",
    "print(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_inputs_data = y_val\n",
    "training_outputs_data = x_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (11063,) for Tensor 'Placeholder_12:0', which has shape '(?, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-104-82805d055a2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m    sess.run(fetches=[train_op], feed_dict={\n\u001b[0;32m      4\u001b[0m                                   \u001b[0mtraining_inputs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtraining_inputs_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m                                   training_outputs: training_outputs_data})   \n\u001b[0m",
      "\u001b[1;32mc:\\users\\algae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 887\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    888\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\algae\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1084\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1086\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1087\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1088\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (11063,) for Tensor 'Placeholder_12:0', which has shape '(?, 3)'"
     ]
    }
   ],
   "source": [
    " # Training loop of the neural network  \n",
    "for step in range(100000):  \n",
    "    sess.run(fetches=[train_op], feed_dict={\n",
    "                                   training_inputs: training_inputs_data,  \n",
    "                                   training_outputs: training_outputs_data})   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val =(b) #I'm trying to convert my reads and sig to tensor here and its not working\n",
    "partial_x_train = (x_val[0:5000])\n",
    "#y_val =(reads[0])\n",
    "#partial_y_train =(reads[0])\n",
    "\n",
    "#x_val=[] # I am trying to resize the reads so that every reads is of a fized length, but it is not working well\n",
    "#for x in range(len(sig)):\n",
    "    #print(sig[x].shape)\n",
    "#    a=len(sig[x])\n",
    "#    sig[x].resize(a,26)\n",
    "#    b=(sig[x])\n",
    "#    for x in len(b):\n",
    "#        a=[str(reads) for reads in sig[x]]\n",
    "#        c=\"\".join(a)\n",
    "#        (temp)\n",
    "#            arr3 = np.array(arr2)\n",
    "    #print(sig[x].shape)\n",
    "#partial_x_train = (x_val[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11063 11063\n"
     ]
    }
   ],
   "source": [
    "print(len(x_val), len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-b993d4ff8672>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m model.compile(optimizer=tf.train.AdamOptimizer(),\n\u001b[0m\u001b[0;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'binary_crossentropy'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m               metrics=['accuracy'])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-2ef40c97ddb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m history = model.fit(partial_x_train,\n\u001b[0m\u001b[0;32m      2\u001b[0m                     \u001b[0mpartial_y_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m256\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=400,\n",
    "                    batch_size=256,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_val, y_val)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-cf3b966a77e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mhistory_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
