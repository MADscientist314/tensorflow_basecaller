{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#from numpy.random import rand\n",
    "#import csv\n",
    "#import h5py\n",
    "#import signal\n",
    "#import fast5\n",
    "#import fastq\n",
    "#import re\n",
    "#import matplotlib.pyplot as plt\n",
    "#import tensorflow as tf\n",
    "#from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "#with tf.device('/gpu:0'):\n",
    "#    a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "#    b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "#    c = tf.matmul(a, b)\n",
    "#with tf.Session() as sess:\n",
    "#   print (sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this function divides the length of whatever \n",
    "size the list is by 4 for a 4mer\n",
    "\"\"\"\n",
    "def BaseFunction(x,y): \n",
    "    return((len(x)//y),y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this function divides the length of whatever \n",
    "size the list is by 40 for a 40mer\n",
    "\"\"\"\n",
    "def SigFunction(x,y): \n",
    "    return((y),((x//y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this function provides information about the array    \n",
    "\"\"\"\n",
    "def array_inspect(x):\n",
    "    print (\"Shape is\",(x.shape))\n",
    "    print((\"Length is\",len(x)))\n",
    "    print((\"Dimension is\",x.ndim))\n",
    "    print((\"Total Size is\",x.size))\n",
    "    print((\"Type is\",x.dtype))\n",
    "    print((\"Type Name is\",x.dtype.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "this function normalizes the raw signal resistances\n",
    "from each read by dividing by the mean(or std?)\n",
    "\"\"\"\n",
    "def normalize(x,y):\n",
    "    z=np.divide(x,y)\n",
    "    #np.savetxt(\"NormalizedSigArray_{}.csv\".format(),(z), delimiter=\",\")\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEVCAYAAAAckrn/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvDW2N/gAAFDZJREFUeJzt3X+w3XV95/HnSyIVEQRMoJREYm1ci8zIQgRmdVZaWggwFpzCKLYlWjRdirvtjP1B7a5QrF3a/eEsXYpDa0rQKqVaNV1i0wxKWadYCRbBSF0iAolECAkiav2BvveP87m7h8vJvZ/ce5NzY56PmTPnnPf38/18Puerc17n+/l+b0hVIUlSj2eNewKSpH2HoSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaGjeSvJAkp/ZA/2+MMk3khywi+1XJHn/HI/59iR/Npd9tn6XJqkkC9r7W5O8ea7H6ZzLG5N8ahxja+8xNDQr7Yv9kSQHD9XenOTWMU7raSaHT1U9VFXPq6rv7605VNUfVNVYvsyluWRoaC4sAH5t3JPQ7pk4O5F2h6GhufBfgN9IctjkDZOXT1rtaUsoSd6S5N4kTyb5QpITR/TzrCSXJflSkh1JbkpyxND2n0uyKcnXWv8/2ervA14I/E1bkvqtEUs6L0ry9238DcDCSWOfmuQfWt+fS3La0LY3Jrm/7fvlJL8w6gANL3kNjb8yyUNJHkvyu7s6uEnOSfJPSb6eZEuSK3bVdiptDh9K8v4kXwfe2HFc/yrJV5M8keS2JC8b2vaCJGvbvD4DvHhoW5K8O8mjbd+7kxw/k3lrfjE0NBc2ArcCv7G7Oya5ALgCuAg4FPg5YMeIpv8BOA94NfBjwOPANa2PlwAfBH4dWASsYxASB1bVLwEPAa9pS1J/NKLvDwB3MgiLdwIrh+Z3DHAz8PvAEe0zfjjJorYkdzVwVlUdAvwb4K7d+PivAv4VcDrwjomgG+GbDI7PYcA5wCVJztuNcYadC3yo9fUXTHFcm48Dy4Ajgc+2fSZcA3wbOBr45faYcAbwb4GXtLFex+j/XbWPMTQ0V94B/Pski3ZzvzcDf1RVd9TA5qp6cES7XwF+t6q2VtV3GATN+e1s4XXAzVW1oaq+B/xX4CAGX+JTSvJC4BXAf6qq71TVbcDfDDX5RWBdVa2rqh9U1QYGIXl22/4D4PgkB1XVtqratBuf/feq6l+q6nPA54CXj2pUVbdW1T1t/LsZBOSrd2OcYbdX1UdbX//C1MeVqlpdVU8ObXt5kue3mwh+HnhHVX2zqj4PrBka53vAIcBLgVTVvVW1bYZz1jxiaGhOtC+N/wVctpu7LgG+1NHuWOAjbYnoa8C9wPeBoxj8Qv5/QVNVPwC2AMd09PtjwONV9c2h2nBoHQtcMDFuG/tVwNFtn9cB/w7YluTmJC/tGHPCV4defwt43qhGSU5J8skk25M80cZbOKpthy2T3u/yuCY5IMlVbenq68ADbZ+FDM7oFkzqb/h/g08A/5PB2cgjSa5LcugM56x5xNDQXLoceAtP/7Ke+DJ+7lDtR4deb2FoLXwKWxgsAx029HhOVX0FeJjBlx8wWE9nEEZfaaWp/innbcDhw3d/MbgGMjzu+yaNe3BVXQVQVeur6mcZLNH8M/CnHZ9ld30AWAssqarnA+8BMsO+Jh+LqY7rGxgsZ/0M8HxgadsnwHbgKQbHecLwcaOqrq6qk4CXMVim+s0ZzlnziKGhOVNVm4G/ZLBOPlHbzuDL+xfbL9df5ukh8WcMLqKf1C6e/kSSY3mm9wDvmtjWrimc27bdBJyT5PQkzwbeBnwH+Ie2/RHgx3cx5wcZLDf9XpIDk7wKeM1Qk/cDr0lyZpv/c5KclmRxkqPaBfiD23jfYPArfa4dAuysqm8nOZnBl/lcmeq4HsLgc+1gEPp/MLFTu135r4Erkjw3yXE8/VrQK9oZ0rMZ/HD4Nnvm2GgvMzQ0164EDp5UewuDX5k7GPzqnPgyp6r+CngXg1/TTwIfZXDBebL/weDX9t8leRL4NHBK6+OLDK49/DHwGIMv/ddU1Xfbvv8Z+I9tCWbUxfo3tL52MjhbumFoflsY/Np+O4Nf11vaZ3lWe7yNwZnOTgbXGX51qoMzQ78KXNk+9zsYhORc2eVxZXAcHmQQ+l9o24a9lcGS2leB64E/H9p2KIOzrsdbHzsYXGvSPi7+R5gkSb0805AkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHVbMO4JzLWFCxfW0qVLxz0NSdqn3HnnnY9V1aLp2v3QhcbSpUvZuHHjuKchSfuUJA/2tHN5SpLUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTth+4vwqV91dLLbh73FMbqgavOmdX++/vxg9kfwx6eaUiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKnbtKGRZEmSTya5N8mmJL/W6kck2ZDkvvZ8eKsnydVJNie5O8mJQ32tbO3vS7JyqH5SknvaPlcnyVRjSJLGo+dM4yngbVX1k8CpwKVJjgMuA26pqmXALe09wFnAsvZYBVwLgwAALgdOAU4GLh8KgWtb24n9VrT6rsaQJI3BtKFRVduq6rPt9ZPAvcAxwLnAmtZsDXBee30ucEMNfBo4LMnRwJnAhqraWVWPAxuAFW3boVV1e1UVcMOkvkaNIUkag926ppFkKfCvgX8EjqqqbTAIFuDI1uwYYMvQbltbbar61hF1phhj8rxWJdmYZOP27dt35yNJknZDd2gkeR7wYeDXq+rrUzUdUasZ1LtV1XVVtbyqli9atGh3dpUk7Yau0EjybAaB8RdV9det/EhbWqI9P9rqW4ElQ7svBh6epr54RH2qMSRJY9Bz91SA9wL3VtV/H9q0Fpi4A2ol8LGh+kXtLqpTgSfa0tJ64Iwkh7cL4GcA69u2J5Oc2sa6aFJfo8aQJI3Bgo42rwR+CbgnyV2t9nbgKuCmJBcDDwEXtG3rgLOBzcC3gDcBVNXOJO8E7mjtrqyqne31JcD1wEHAx9uDKcaQJI3BtKFRVZ9i9HUHgNNHtC/g0l30tRpYPaK+ETh+RH3HqDEkSePhX4RLkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6tbzX+6Tuiy97OZxT2GsHrjqnHFPQdrjPNOQJHUzNCRJ3QwNSVI3Q0OS1M0L4UO8kOuFXElT80xDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndpg2NJKuTPJrk80O1K5J8Jcld7XH20LbfSbI5yReTnDlUX9Fqm5NcNlR/UZJ/THJfkr9McmCr/0h7v7ltXzpXH1qSNDM9ZxrXAytG1N9dVSe0xzqAJMcBrwde1vb5kyQHJDkAuAY4CzgOuLC1BfjD1tcy4HHg4la/GHi8qn4CeHdrJ0kao2lDo6puA3Z29ncucGNVfaeqvgxsBk5uj81VdX9VfRe4ETg3SYCfBj7U9l8DnDfU15r2+kPA6a29JGlMZnNN461J7m7LV4e32jHAlqE2W1ttV/UXAF+rqqcm1Z/WV9v+RGv/DElWJdmYZOP27dtn8ZEkSVOZaWhcC7wYOAHYBvy3Vh91JlAzqE/V1zOLVddV1fKqWr5o0aKp5i1JmoUZhUZVPVJV36+qHwB/ymD5CQZnCkuGmi4GHp6i/hhwWJIFk+pP66ttfz79y2SSpD1gRqGR5Oiht68FJu6sWgu8vt359CJgGfAZ4A5gWbtT6kAGF8vXVlUBnwTOb/uvBD421NfK9vp84BOtvSRpTBZM1yDJB4HTgIVJtgKXA6clOYHBctEDwK8AVNWmJDcBXwCeAi6tqu+3ft4KrAcOAFZX1aY2xG8DNyb5feCfgPe2+nuB9yXZzOAM4/Wz/rSSpFmZNjSq6sIR5feOqE20fxfwrhH1dcC6EfX7+f/LW8P1bwMXTDc/SdLe41+ES5K6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6GRqSpG6GhiSpm6EhSepmaEiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6mZoSJK6TRsaSVYneTTJ54dqRyTZkOS+9nx4qyfJ1Uk2J7k7yYlD+6xs7e9LsnKoflKSe9o+VyfJVGNIksan50zjemDFpNplwC1VtQy4pb0HOAtY1h6rgGthEADA5cApwMnA5UMhcG1rO7HfimnGkCSNybShUVW3ATsnlc8F1rTXa4Dzhuo31MCngcOSHA2cCWyoqp1V9TiwAVjRth1aVbdXVQE3TOpr1BiSpDGZ6TWNo6pqG0B7PrLVjwG2DLXb2mpT1beOqE81xjMkWZVkY5KN27dvn+FHkiRNZ64vhGdErWZQ3y1VdV1VLa+q5YsWLdrd3SVJnWYaGo+0pSXa86OtvhVYMtRuMfDwNPXFI+pTjSFJGpOZhsZaYOIOqJXAx4bqF7W7qE4FnmhLS+uBM5Ic3i6AnwGsb9ueTHJqu2vqokl9jRpDkjQmC6ZrkOSDwGnAwiRbGdwFdRVwU5KLgYeAC1rzdcDZwGbgW8CbAKpqZ5J3Ane0dldW1cTF9UsY3KF1EPDx9mCKMSRJYzJtaFTVhbvYdPqItgVcuot+VgOrR9Q3AsePqO8YNYYkaXz8i3BJUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUrdZhUaSB5Lck+SuJBtb7YgkG5Lc154Pb/UkuTrJ5iR3JzlxqJ+Vrf19SVYO1U9q/W9u+2Y285Ukzc5cnGn8VFWdUFXL2/vLgFuqahlwS3sPcBawrD1WAdfCIGSAy4FTgJOByyeCprVZNbTfijmYryRphvbE8tS5wJr2eg1w3lD9hhr4NHBYkqOBM4ENVbWzqh4HNgAr2rZDq+r2qirghqG+JEljMNvQKODvktyZZFWrHVVV2wDa85GtfgywZWjfra02VX3riPozJFmVZGOSjdu3b5/lR5Ik7cqCWe7/yqp6OMmRwIYk/zxF21HXI2oG9WcWq64DrgNYvnz5yDaSpNmb1ZlGVT3cnh8FPsLgmsQjbWmJ9vxoa74VWDK0+2Lg4Wnqi0fUJUljMuPQSHJwkkMmXgNnAJ8H1gITd0CtBD7WXq8FLmp3UZ0KPNGWr9YDZyQ5vF0APwNY37Y9meTUdtfURUN9SZLGYDbLU0cBH2l3wS4APlBVf5vkDuCmJBcDDwEXtPbrgLOBzcC3gDcBVNXOJO8E7mjtrqyqne31JcD1wEHAx9tDkjQmMw6NqrofePmI+g7g9BH1Ai7dRV+rgdUj6huB42c6R0nS3PIvwiVJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHUzNCRJ3QwNSVI3Q0OS1M3QkCR1MzQkSd0MDUlSN0NDktTN0JAkdTM0JEndDA1JUjdDQ5LUzdCQJHWb96GRZEWSLybZnOSycc9HkvZn8zo0khwAXAOcBRwHXJjkuPHOSpL2X/M6NICTgc1VdX9VfRe4ETh3zHOSpP3WfA+NY4AtQ++3tpokaQwWjHsC08iIWj2jUbIKWNXefiPJF/forPachcBj4xo8fziukeeMx292PH6zM9bjB7M+hsf2NJrvobEVWDL0fjHw8ORGVXUdcN3emtSekmRjVS0f9zz2VR6/2fH4zc7+cvzm+/LUHcCyJC9KciDwemDtmOckSfuteX2mUVVPJXkrsB44AFhdVZvGPC1J2m/N69AAqKp1wLpxz2Mv2eeX2MbM4zc7Hr/Z2S+OX6qecV1ZkqSR5vs1DUnSPGJozBNJXpukkrx03HPZlyR5QZK72uOrSb4y9P7Acc9vX5DkqCQfSHJ/kjuT3J7kteOe174kyY8muTHJl5J8Icm6JC8Z97z2BENj/rgQ+BSDO8TUqap2VNUJVXUC8B7g3RPv278ioCkkCfBR4Laq+vGqOonB/wcXj3dm+452DD8C3FpVL66q44C3A0eNd2Z7hqExDyR5HvBK4GIMDe1dPw18t6reM1Goqger6o/HOKd9zU8B35t0DO+qqv89xjntMYbG/HAe8LdV9X+AnUlOHPeEtN94GfDZcU9iH3c8cOe4J7G3GBrzw4UM/jFG2vOFY5yL9mNJrknyuSR3jHsump/m/d9p/LBL8gIGSwTHJykGf8RYSX6rvB9ae94m4Ocn3lTVpUkWAhvHN6V9zibg/HFPYm/xTGP8zgduqKpjq2ppVS0Bvgy8aszz0v7hE8BzklwyVHvuuCazj/oE8CNJ3jJRSPKKJK8e45z2GENj/C5kcOfFsA8DbxjDXLSfaWez5wGvTvLlJJ8B1gC/Pd6Z7TvaMXwt8LPtlttNwBWM+MdVfxj4F+GSpG6eaUiSuhkakqRuhoYkqZuhIUnqZmhIkroZGpKkboaGJKmboSFJ6vZ/ASXN7wYXNWOeAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell does the following\n",
    "    1)Imports the bases\n",
    "    2)trims off the new lines and digits\n",
    "    3)converts them to a list\n",
    "    4)converts them to a code of 0123 instead of ATCG\n",
    "\"\"\"\n",
    "f = open(\"fasta/sampled_read.fasta\",\"r\") #opens the file with the reads\n",
    "a = f.read()\n",
    "b = (a.split(\">\", 12))\n",
    "base = [re.sub(\">|\\n|\\d\", \"\",str) for str in b]\n",
    "baseA0 = [re.sub(\"A\",\"0\",str) for str in base]\n",
    "baseT1 = [re.sub(\"T\",\"1\",str) for str in baseA0]\n",
    "baseG2 = [re.sub(\"C\",\"2\",str) for str in baseT1]\n",
    "base_coded = [re.sub(\"G\",\"3\",str) for str in baseG2] \n",
    "A0=(a.count(\"A\")) \n",
    "T1=(a.count(\"T\"))\n",
    "G2=(a.count(\"G\"))\n",
    "C3=(a.count(\"C\"))\n",
    "names = ['A', 'T', 'G', 'C']\n",
    "values = [(A0), (T1), (G2), (C3)]\n",
    "plt.subplot()\n",
    "plt.bar(names, values)\n",
    "plt.suptitle('Nucleotides in all reads')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The purpose of this code is the following\n",
    "1)Convert the coded reads to integer form \n",
    "2)Create an array inside the array with each read as a row\n",
    "3)Create a 2D matric with the counts of all the possible scenarios \n",
    "presented in each row and the reads in each column\n",
    "4)Create a 1D array with the readlengths\n",
    "\"\"\"\n",
    "kmer=[]\n",
    "kmercount=[]\n",
    "reads=[]\n",
    "#readstring={}\n",
    "readslength=[]\n",
    "res=(len(base_coded))   \n",
    "for x in range(res):\n",
    "    l=list(int (i) for i in base_coded[x])\n",
    "    for y in range(1):\n",
    "        i=(l.count(y), l.count(y+1), l.count(y+2), l.count(y+3))\n",
    "        kmercount.append(i)\n",
    "        n=np.transpose(kmercount) # creates a 2D matrix with the bases counts as rows(ATGC) and the reads by columns\n",
    "        kmer = n.view() #Create a view of the array with the same data\n",
    "    d=np.asarray(l)\n",
    "    d.resize((BaseFunction(d,6))) #Enter the list and the desired kmer for the function\n",
    "    v=(str(d))\n",
    "    reads.append(d) # store the reads in an array called reads\n",
    "    c=len(d)\n",
    "    readslength.append(c) #store the amt of kmer reads in readlength="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "The purpose of this code is the following\n",
    "1) visualize the readlengths\n",
    "\"\"\"\n",
    "plt.ioff()\n",
    "for i in range(1):\n",
    "    plt.title(\"Readlengths\")\n",
    "    plt.ylabel('number of bases')\n",
    "    plt.xlabel('read id')\n",
    "    plt.plot(kmer[i])\n",
    "    plt.xticks(np.arange(0, 12))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The cell does the following:\n",
    "    1) Import the signal level data\n",
    "    2) Normalize it to the mean fof the signal\n",
    "    3) Appends the signal data from each read into a row of an array given the read count\n",
    "\"\"\"\n",
    "means = [] \n",
    "std = []\n",
    "sig = []\n",
    "for x in range(12):\n",
    "    a=np.loadtxt(\"signal/signal_{}.txt\".format(x)) # load the signal\n",
    "    m=a.mean() #obtain the average signal from the read\n",
    "    b=normalize(m,a) # divide each resistance by the average to normalize \n",
    "    c=b.size #obtains the number of resistance signals per read\n",
    "    #print(\"resist\",c)\n",
    "    d=readslength[x] #obtains the kmers count per read\n",
    "    #print(\"kmer\",d)\n",
    "    e=SigFunction(c,d) #figures out the average amount of resistances per kmer\n",
    "    #print(\"Signal\",x,\"2D array size={}\".format(e))\n",
    "    b.resize(e) # Insert the (#bases,#sig) changes the signal level n signals wide\n",
    "    sig.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The goal for this cell is to convert the reads to string\n",
    "index the unique outputs for the 4mers\n",
    "and create a new list of the indexed [1:256 or whatever]\n",
    "reads for the model\n",
    "\"\"\"\n",
    "arr2=[] # In this code I converted the reads to a concated string of a 4mer\n",
    "converted=[]\n",
    "converted2=[]\n",
    "for i, v in enumerate(reads[11]): #Read 0 is the training data\n",
    "    temp = ''\n",
    "    for w in v:\n",
    "        temp = temp + str(w)\n",
    "    arr2.append(temp)\n",
    "a=np.unique(arr2) # makes an array of every unique combo in the read for downstream indexing\n",
    "for x in arr2:\n",
    "    #print(x)\n",
    "    b=enumerate(a)\n",
    "    c=[(i) for i, j in b if a[i]==(x)]\n",
    "    converted.append(c)\n",
    "for i, v in enumerate(converted): #Read 0 is the training data\n",
    "    temp = ''\n",
    "    #print(v)\n",
    "    for w in v:\n",
    "        #print(w)\n",
    "        temp = temp + str(w)\n",
    "    converted2.append(temp)\n",
    "y_train=np.int16(converted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4083\n"
     ]
    }
   ],
   "source": [
    "print(a.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1927\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "I just copied the same code for the testing set read(1)\n",
    "\"\"\"\n",
    "arr2=[] # In this code I converted the reads to a concated string of a 4mer\n",
    "converted=[]\n",
    "converted2=[]\n",
    "for i, v in enumerate(reads[10]): #Read 0 is the training data\n",
    "    temp = ''\n",
    "    for w in v:\n",
    "        temp = temp + str(w)\n",
    "    arr2.append(temp)\n",
    "a=np.unique(arr2)# makes an array of every unique combo in the read for downstream indexing\n",
    "for x in arr2:\n",
    "    #print(x)\n",
    "    b=enumerate(a)\n",
    "    c=[(i) for i, j in b if a[i]==(x)]\n",
    "    converted.append(c)\n",
    "for i, v in enumerate(converted): #Read 0 is the training data\n",
    "    temp = ''\n",
    "    for w in v:\n",
    "        temp = temp + str(w)\n",
    "    converted2.append(temp)\n",
    "n=np.unique(converted2)\n",
    "print((n.size))\n",
    "y_test=np.int16(converted2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is (118518, 40)\n",
      "('Length is', 118518)\n",
      "('Dimension is', 2)\n",
      "('Total Size is', 4740720)\n",
      "('Type is', dtype('float64'))\n",
      "('Type Name is', 'float64')\n"
     ]
    }
   ],
   "source": [
    "x_train = sig[11]\n",
    "x_test = sig[10]\n",
    "array_inspect(x_train)\n",
    "(i,j) = x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_2/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create checkpoint callback\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, \n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "\n",
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu)) # uses 128 neurons and is a feed forward rectilinear relu\n",
    "model.add(tf.keras.layers.Dense(256, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(512, activation=tf.nn.relu))\n",
    "model.add(tf.keras.layers.Dense(1024, activation=tf.nn.relu)) # do the same thig for hidden layer 2\n",
    "model.add(tf.keras.layers.Dense(2048, activation=tf.nn.relu)) # do the same thig for hidden layer 2\n",
    "model.add(tf.keras.layers.Dense(4096, activation=tf.nn.softmax)) # output layer with number of classifications (256) use softmax for output distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 118518 samples, validate on 10000 samples\n",
      "Epoch 1/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9675 - acc: 0.0021\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9682 - acc: 0.0021 - val_loss: 7.9405 - val_acc: 0.0033\n",
      "Epoch 2/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9679 - acc: 0.0022\n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9681 - acc: 0.0022 - val_loss: 7.9394 - val_acc: 0.0029\n",
      "Epoch 3/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9687 - acc: 0.0019- ETA: 1s - loss: 7.96\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9686 - acc: 0.0020 - val_loss: 7.9398 - val_acc: 0.0032\n",
      "Epoch 4/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9674 - acc: 0.0021\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9672 - acc: 0.0021 - val_loss: 7.9386 - val_acc: 0.0027\n",
      "Epoch 5/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9679 - acc: 0.0021\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9677 - acc: 0.0021 - val_loss: 7.9386 - val_acc: 0.0026\n",
      "Epoch 6/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9677 - acc: 0.0020\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9672 - acc: 0.0020 - val_loss: 7.9386 - val_acc: 0.0027\n",
      "Epoch 7/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9671 - acc: 0.0022\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9671 - acc: 0.0022 - val_loss: 7.9381 - val_acc: 0.0029\n",
      "Epoch 8/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9670 - acc: 0.0021\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9671 - acc: 0.0022 - val_loss: 7.9386 - val_acc: 0.0030\n",
      "Epoch 9/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9667 - acc: 0.0023\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9667 - acc: 0.0022 - val_loss: 7.9392 - val_acc: 0.0028\n",
      "Epoch 10/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9659 - acc: 0.0022\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9666 - acc: 0.0022 - val_loss: 7.9396 - val_acc: 0.0032\n",
      "Epoch 11/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9664 - acc: 0.0021\n",
      "Epoch 00011: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9663 - acc: 0.0021 - val_loss: 7.9390 - val_acc: 0.0029\n",
      "Epoch 12/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9660 - acc: 0.0022\n",
      "Epoch 00012: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9662 - acc: 0.0022 - val_loss: 7.9391 - val_acc: 0.0028\n",
      "Epoch 13/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9665 - acc: 0.0021\n",
      "Epoch 00013: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9661 - acc: 0.0021 - val_loss: 7.9382 - val_acc: 0.0028\n",
      "Epoch 14/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9659 - acc: 0.0022\n",
      "Epoch 00014: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9662 - acc: 0.0022 - val_loss: 7.9383 - val_acc: 0.0026\n",
      "Epoch 15/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9646 - acc: 0.0023\n",
      "Epoch 00015: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9654 - acc: 0.0022 - val_loss: 7.9415 - val_acc: 0.0028\n",
      "Epoch 16/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9657 - acc: 0.0022\n",
      "Epoch 00016: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9661 - acc: 0.0022 - val_loss: 7.9387 - val_acc: 0.0034\n",
      "Epoch 17/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9662 - acc: 0.0024\n",
      "Epoch 00017: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9661 - acc: 0.0024 - val_loss: 7.9399 - val_acc: 0.0026\n",
      "Epoch 18/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9650 - acc: 0.0022\n",
      "Epoch 00018: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9657 - acc: 0.0022 - val_loss: 7.9378 - val_acc: 0.0029\n",
      "Epoch 19/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9643 - acc: 0.0022\n",
      "Epoch 00019: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9650 - acc: 0.0022 - val_loss: 7.9377 - val_acc: 0.0029\n",
      "Epoch 20/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9649 - acc: 0.0022\n",
      "Epoch 00020: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9650 - acc: 0.0022 - val_loss: 7.9367 - val_acc: 0.0029\n",
      "Epoch 21/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9653 - acc: 0.0021\n",
      "Epoch 00021: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9653 - acc: 0.0021 - val_loss: 7.9387 - val_acc: 0.0022\n",
      "Epoch 22/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9651 - acc: 0.0021\n",
      "Epoch 00022: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9653 - acc: 0.0021 - val_loss: 7.9380 - val_acc: 0.0028\n",
      "Epoch 23/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9641 - acc: 0.0023\n",
      "Epoch 00023: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9648 - acc: 0.0023 - val_loss: 7.9378 - val_acc: 0.0028\n",
      "Epoch 24/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9653 - acc: 0.0023\n",
      "Epoch 00024: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9654 - acc: 0.0023 - val_loss: 7.9385 - val_acc: 0.0029\n",
      "Epoch 25/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9641 - acc: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00025: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9646 - acc: 0.0022 - val_loss: 7.9369 - val_acc: 0.0034\n",
      "Epoch 26/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9651 - acc: 0.0023\n",
      "Epoch 00026: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9651 - acc: 0.0023 - val_loss: 7.9366 - val_acc: 0.0028\n",
      "Epoch 27/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9632 - acc: 0.0023\n",
      "Epoch 00027: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9647 - acc: 0.0023 - val_loss: 7.9393 - val_acc: 0.0029\n",
      "Epoch 28/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9660 - acc: 0.0022\n",
      "Epoch 00028: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9674 - acc: 0.0022 - val_loss: 7.9381 - val_acc: 0.0030\n",
      "Epoch 29/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9648 - acc: 0.0022\n",
      "Epoch 00029: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9652 - acc: 0.0021 - val_loss: 7.9368 - val_acc: 0.0033\n",
      "Epoch 30/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9639 - acc: 0.0023\n",
      "Epoch 00030: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9644 - acc: 0.0023 - val_loss: 7.9385 - val_acc: 0.0029\n",
      "Epoch 31/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9638 - acc: 0.0024\n",
      "Epoch 00031: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9639 - acc: 0.0024 - val_loss: 7.9369 - val_acc: 0.0032\n",
      "Epoch 32/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9648 - acc: 0.0021\n",
      "Epoch 00032: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9651 - acc: 0.0021 - val_loss: 7.9374 - val_acc: 0.0027\n",
      "Epoch 33/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9646 - acc: 0.0022\n",
      "Epoch 00033: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9647 - acc: 0.0022 - val_loss: 7.9360 - val_acc: 0.0028\n",
      "Epoch 34/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9635 - acc: 0.0023\n",
      "Epoch 00034: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9640 - acc: 0.0023 - val_loss: 7.9366 - val_acc: 0.0029\n",
      "Epoch 35/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9643 - acc: 0.0022\n",
      "Epoch 00035: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9643 - acc: 0.0022 - val_loss: 7.9361 - val_acc: 0.0030\n",
      "Epoch 36/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9632 - acc: 0.0022\n",
      "Epoch 00036: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9631 - acc: 0.0022 - val_loss: 7.9360 - val_acc: 0.0032\n",
      "Epoch 37/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9619 - acc: 0.0021\n",
      "Epoch 00037: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9635 - acc: 0.0021 - val_loss: 7.9374 - val_acc: 0.0026\n",
      "Epoch 38/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9645 - acc: 0.0023\n",
      "Epoch 00038: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9649 - acc: 0.0023 - val_loss: 7.9360 - val_acc: 0.0033\n",
      "Epoch 39/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9638 - acc: 0.0024\n",
      "Epoch 00039: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9644 - acc: 0.0024 - val_loss: 7.9356 - val_acc: 0.0031\n",
      "Epoch 40/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9639 - acc: 0.0022\n",
      "Epoch 00040: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9640 - acc: 0.0022 - val_loss: 7.9356 - val_acc: 0.0030\n",
      "Epoch 41/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9624 - acc: 0.0022\n",
      "Epoch 00041: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9633 - acc: 0.0022 - val_loss: 7.9356 - val_acc: 0.0032\n",
      "Epoch 42/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9630 - acc: 0.0023\n",
      "Epoch 00042: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9631 - acc: 0.0023 - val_loss: 7.9350 - val_acc: 0.0032\n",
      "Epoch 43/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9620 - acc: 0.0022\n",
      "Epoch 00043: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9626 - acc: 0.0022 - val_loss: 7.9355 - val_acc: 0.0026\n",
      "Epoch 44/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9628 - acc: 0.0023\n",
      "Epoch 00044: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9627 - acc: 0.0023 - val_loss: 7.9356 - val_acc: 0.0033\n",
      "Epoch 45/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9613 - acc: 0.0023\n",
      "Epoch 00045: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9622 - acc: 0.0023 - val_loss: 7.9347 - val_acc: 0.0027\n",
      "Epoch 46/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9615 - acc: 0.0022\n",
      "Epoch 00046: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9622 - acc: 0.0023 - val_loss: 7.9352 - val_acc: 0.0029\n",
      "Epoch 47/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9618 - acc: 0.0023\n",
      "Epoch 00047: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9621 - acc: 0.0023 - val_loss: 7.9345 - val_acc: 0.0032\n",
      "Epoch 48/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9624 - acc: 0.0023\n",
      "Epoch 00048: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9620 - acc: 0.0023 - val_loss: 7.9338 - val_acc: 0.0030\n",
      "Epoch 49/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9617 - acc: 0.0023\n",
      "Epoch 00049: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9621 - acc: 0.0023 - val_loss: 7.9353 - val_acc: 0.0030\n",
      "Epoch 50/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9615 - acc: 0.0024\n",
      "Epoch 00050: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9621 - acc: 0.0024 - val_loss: 7.9359 - val_acc: 0.0031\n",
      "Epoch 51/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9621 - acc: 0.0023\n",
      "Epoch 00051: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9621 - acc: 0.0022 - val_loss: 7.9371 - val_acc: 0.0031\n",
      "Epoch 52/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9621 - acc: 0.0024\n",
      "Epoch 00052: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9622 - acc: 0.0024 - val_loss: 7.9334 - val_acc: 0.0032\n",
      "Epoch 53/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9627 - acc: 0.0024\n",
      "Epoch 00053: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9621 - acc: 0.0024 - val_loss: 7.9342 - val_acc: 0.0032\n",
      "Epoch 54/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9620 - acc: 0.0023\n",
      "Epoch 00054: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9621 - acc: 0.0023 - val_loss: 7.9342 - val_acc: 0.0031\n",
      "Epoch 55/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9623 - acc: 0.0023\n",
      "Epoch 00055: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9615 - acc: 0.0023 - val_loss: 7.9343 - val_acc: 0.0032\n",
      "Epoch 56/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9610 - acc: 0.0024\n",
      "Epoch 00056: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9611 - acc: 0.0024 - val_loss: 7.9334 - val_acc: 0.0028\n",
      "Epoch 57/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9604 - acc: 0.0023\n",
      "Epoch 00057: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9614 - acc: 0.0022 - val_loss: 7.9336 - val_acc: 0.0029\n",
      "Epoch 58/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9623 - acc: 0.0024\n",
      "Epoch 00058: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9619 - acc: 0.0023 - val_loss: 7.9333 - val_acc: 0.0030\n",
      "Epoch 59/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9608 - acc: 0.0023\n",
      "Epoch 00059: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9610 - acc: 0.0023 - val_loss: 7.9330 - val_acc: 0.0036\n",
      "Epoch 60/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9609 - acc: 0.0023\n",
      "Epoch 00060: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9611 - acc: 0.0023 - val_loss: 7.9343 - val_acc: 0.0032\n",
      "Epoch 61/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9617 - acc: 0.0022\n",
      "Epoch 00061: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9612 - acc: 0.0022 - val_loss: 7.9339 - val_acc: 0.0033\n",
      "Epoch 62/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9601 - acc: 0.0024\n",
      "Epoch 00062: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9606 - acc: 0.0024 - val_loss: 7.9354 - val_acc: 0.0032\n",
      "Epoch 63/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9610 - acc: 0.0024\n",
      "Epoch 00063: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9615 - acc: 0.0024 - val_loss: 7.9341 - val_acc: 0.0032\n",
      "Epoch 64/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9619 - acc: 0.0023\n",
      "Epoch 00064: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9614 - acc: 0.0023 - val_loss: 7.9331 - val_acc: 0.0029\n",
      "Epoch 65/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9610 - acc: 0.0023\n",
      "Epoch 00065: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9606 - acc: 0.0023 - val_loss: 7.9329 - val_acc: 0.0031\n",
      "Epoch 66/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9602 - acc: 0.0024- ETA: 0s - loss: 7.9591 - acc: 0.0\n",
      "Epoch 00066: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9606 - acc: 0.0024 - val_loss: 7.9340 - val_acc: 0.0034\n",
      "Epoch 67/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9608 - acc: 0.0024\n",
      "Epoch 00067: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9611 - acc: 0.0024 - val_loss: 7.9361 - val_acc: 0.0033\n",
      "Epoch 68/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9616 - acc: 0.0023\n",
      "Epoch 00068: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9614 - acc: 0.0023 - val_loss: 7.9326 - val_acc: 0.0035\n",
      "Epoch 69/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9598 - acc: 0.0023\n",
      "Epoch 00069: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9597 - acc: 0.0024 - val_loss: 7.9319 - val_acc: 0.0031\n",
      "Epoch 70/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9606 - acc: 0.0024\n",
      "Epoch 00070: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9604 - acc: 0.0024 - val_loss: 7.9329 - val_acc: 0.0030\n",
      "Epoch 71/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9608 - acc: 0.0025\n",
      "Epoch 00071: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9606 - acc: 0.0024 - val_loss: 7.9322 - val_acc: 0.0034\n",
      "Epoch 72/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9595 - acc: 0.0024\n",
      "Epoch 00072: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9602 - acc: 0.0024 - val_loss: 7.9342 - val_acc: 0.0030\n",
      "Epoch 73/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9613 - acc: 0.0023\n",
      "Epoch 00073: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9611 - acc: 0.0023 - val_loss: 7.9342 - val_acc: 0.0033\n",
      "Epoch 74/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9593 - acc: 0.0024\n",
      "Epoch 00074: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9594 - acc: 0.0024 - val_loss: 7.9323 - val_acc: 0.0034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9594 - acc: 0.0025\n",
      "Epoch 00075: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9596 - acc: 0.0024 - val_loss: 7.9327 - val_acc: 0.0036\n",
      "Epoch 76/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9600 - acc: 0.0024\n",
      "Epoch 00076: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9599 - acc: 0.0023 - val_loss: 7.9311 - val_acc: 0.0028\n",
      "Epoch 77/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9599 - acc: 0.0024\n",
      "Epoch 00077: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9597 - acc: 0.0024 - val_loss: 7.9307 - val_acc: 0.0030\n",
      "Epoch 78/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9589 - acc: 0.0025\n",
      "Epoch 00078: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9594 - acc: 0.0025 - val_loss: 7.9323 - val_acc: 0.0029\n",
      "Epoch 79/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9591 - acc: 0.0024\n",
      "Epoch 00079: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9593 - acc: 0.0024 - val_loss: 7.9332 - val_acc: 0.0032\n",
      "Epoch 80/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9592 - acc: 0.0024\n",
      "Epoch 00080: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9595 - acc: 0.0024 - val_loss: 7.9317 - val_acc: 0.0041\n",
      "Epoch 81/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9586 - acc: 0.0024\n",
      "Epoch 00081: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9588 - acc: 0.0023 - val_loss: 7.9316 - val_acc: 0.0037\n",
      "Epoch 82/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9593 - acc: 0.0024- ETA: 0s - loss: 7.9579 - \n",
      "Epoch 00082: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9593 - acc: 0.0023 - val_loss: 7.9326 - val_acc: 0.0033\n",
      "Epoch 83/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9583 - acc: 0.0024\n",
      "Epoch 00083: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9592 - acc: 0.0024 - val_loss: 7.9307 - val_acc: 0.0034\n",
      "Epoch 84/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9590 - acc: 0.0023\n",
      "Epoch 00084: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9592 - acc: 0.0024 - val_loss: 7.9320 - val_acc: 0.0027\n",
      "Epoch 85/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9591 - acc: 0.0025\n",
      "Epoch 00085: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9587 - acc: 0.0025 - val_loss: 7.9301 - val_acc: 0.0035\n",
      "Epoch 86/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9576 - acc: 0.0025\n",
      "Epoch 00086: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9583 - acc: 0.0024 - val_loss: 7.9308 - val_acc: 0.0033\n",
      "Epoch 87/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9583 - acc: 0.0025\n",
      "Epoch 00087: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9584 - acc: 0.0025 - val_loss: 7.9312 - val_acc: 0.0027\n",
      "Epoch 88/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9582 - acc: 0.0025\n",
      "Epoch 00088: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9590 - acc: 0.0025 - val_loss: 7.9301 - val_acc: 0.0035\n",
      "Epoch 89/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9593 - acc: 0.0024\n",
      "Epoch 00089: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9591 - acc: 0.0024 - val_loss: 7.9337 - val_acc: 0.0037\n",
      "Epoch 90/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9578 - acc: 0.0025\n",
      "Epoch 00090: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9583 - acc: 0.0025 - val_loss: 7.9328 - val_acc: 0.0035\n",
      "Epoch 91/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9579 - acc: 0.0024\n",
      "Epoch 00091: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9583 - acc: 0.0024 - val_loss: 7.9304 - val_acc: 0.0035\n",
      "Epoch 92/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9595 - acc: 0.0026\n",
      "Epoch 00092: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9600 - acc: 0.0025 - val_loss: 7.9304 - val_acc: 0.0029\n",
      "Epoch 93/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9588 - acc: 0.0025\n",
      "Epoch 00093: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9591 - acc: 0.0025 - val_loss: 7.9299 - val_acc: 0.0034\n",
      "Epoch 94/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9577 - acc: 0.0026\n",
      "Epoch 00094: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9576 - acc: 0.0025 - val_loss: 7.9296 - val_acc: 0.0033\n",
      "Epoch 95/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9573 - acc: 0.0024\n",
      "Epoch 00095: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9573 - acc: 0.0024 - val_loss: 7.9297 - val_acc: 0.0033\n",
      "Epoch 96/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9568 - acc: 0.0025\n",
      "Epoch 00096: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9574 - acc: 0.0025 - val_loss: 7.9321 - val_acc: 0.0037\n",
      "Epoch 97/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9570 - acc: 0.0024\n",
      "Epoch 00097: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9578 - acc: 0.0024 - val_loss: 7.9289 - val_acc: 0.0028\n",
      "Epoch 98/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9575 - acc: 0.0026\n",
      "Epoch 00098: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9575 - acc: 0.0026 - val_loss: 7.9305 - val_acc: 0.0032\n",
      "Epoch 99/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9563 - acc: 0.0026\n",
      "Epoch 00099: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9575 - acc: 0.0025 - val_loss: 7.9322 - val_acc: 0.0034\n",
      "Epoch 100/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9572 - acc: 0.0025\n",
      "Epoch 00100: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9574 - acc: 0.0025 - val_loss: 7.9312 - val_acc: 0.0033\n",
      "Epoch 101/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9571 - acc: 0.0026\n",
      "Epoch 00101: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9566 - acc: 0.0026 - val_loss: 7.9316 - val_acc: 0.0032\n",
      "Epoch 102/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9568 - acc: 0.0024\n",
      "Epoch 00102: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9570 - acc: 0.0024 - val_loss: 7.9314 - val_acc: 0.0035\n",
      "Epoch 103/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9570 - acc: 0.0024\n",
      "Epoch 00103: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9567 - acc: 0.0025 - val_loss: 7.9307 - val_acc: 0.0030\n",
      "Epoch 104/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9565 - acc: 0.0025\n",
      "Epoch 00104: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9567 - acc: 0.0024 - val_loss: 7.9291 - val_acc: 0.0031\n",
      "Epoch 105/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9564 - acc: 0.0025\n",
      "Epoch 00105: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 17us/step - loss: 7.9567 - acc: 0.0025 - val_loss: 7.9291 - val_acc: 0.0030\n",
      "Epoch 106/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9554 - acc: 0.0025\n",
      "Epoch 00106: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9565 - acc: 0.0025 - val_loss: 7.9299 - val_acc: 0.0032\n",
      "Epoch 107/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9575 - acc: 0.0025\n",
      "Epoch 00107: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9572 - acc: 0.0025 - val_loss: 7.9339 - val_acc: 0.0033\n",
      "Epoch 108/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9567 - acc: 0.0024\n",
      "Epoch 00108: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9567 - acc: 0.0024 - val_loss: 7.9301 - val_acc: 0.0032\n",
      "Epoch 109/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9563 - acc: 0.0025\n",
      "Epoch 00109: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9564 - acc: 0.0025 - val_loss: 7.9299 - val_acc: 0.0032\n",
      "Epoch 110/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9555 - acc: 0.0025\n",
      "Epoch 00110: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9561 - acc: 0.0025 - val_loss: 7.9299 - val_acc: 0.0036\n",
      "Epoch 111/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9553 - acc: 0.0024\n",
      "Epoch 00111: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9561 - acc: 0.0024 - val_loss: 7.9332 - val_acc: 0.0032\n",
      "Epoch 112/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9557 - acc: 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00112: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9560 - acc: 0.0025 - val_loss: 7.9294 - val_acc: 0.0029\n",
      "Epoch 113/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9551 - acc: 0.0026\n",
      "Epoch 00113: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9553 - acc: 0.0026 - val_loss: 7.9293 - val_acc: 0.0032\n",
      "Epoch 114/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9544 - acc: 0.0026\n",
      "Epoch 00114: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9555 - acc: 0.0026 - val_loss: 7.9300 - val_acc: 0.0031\n",
      "Epoch 115/10000\n",
      "114688/118518 [============================>.] - ETA: 0s - loss: 7.9556 - acc: 0.0027\n",
      "Epoch 00115: saving model to training_1/cp.ckpt\n",
      "WARNING:tensorflow:This model was compiled with a Keras optimizer (<tensorflow.python.keras.optimizers.Adam object at 0x0000020DFE60E9E8>) but is being saved in TensorFlow format with `save_weights`. The model's weights will be saved, but unlike with TensorFlow optimizers in the TensorFlow format the optimizer's state will not be saved.\n",
      "\n",
      "Consider using a TensorFlow optimizer from `tf.train`.\n",
      "118518/118518 [==============================] - 2s 18us/step - loss: 7.9555 - acc: 0.0027 - val_loss: 7.9275 - val_acc: 0.0033\n",
      "Epoch 116/10000\n",
      " 20480/118518 [====>.........................] - ETA: 1s - loss: 7.9499 - acc: 0.0030"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-dc6df4b8ad3a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4096\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m                     callbacks = [cp_callback])\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\philip\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1603\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1604\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1605\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1606\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1607\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\philip\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    212\u001b[0m           \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m           \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\philip\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2976\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2977\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 2978\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   2979\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2980\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\philip\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "x_val = x_train[:10000]\n",
    "partial_x_train = x_train\n",
    "\n",
    "y_val = y_train[:10000]\n",
    "partial_y_train = y_train\n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=10000,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    batch_size=4096,\n",
    "                    verbose=1,\n",
    "                    callbacks = [cp_callback])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "118518/118518 [==============================] - 7s 55us/step\n",
      "[2.2478100991590666, 0.5141750620171536]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_train, y_train)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\" is for \"blue dot\"\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b is for \"solid blue line\"\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.argmax(predictions[0])) #why is 85 the max number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_inspect(x_test)\n",
    "array_inspect(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
